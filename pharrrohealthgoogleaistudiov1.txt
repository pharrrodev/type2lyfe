PharrroHealth: AI Diabetes Assistant - Technical Report & Backend Specification
Part 1: Frontend Technical Report
1. Introduction & Vision
PharrroHealth is a modern, AI-powered mobile web application designed to simplify diabetes and health management. It serves as a personal health assistant, allowing users to track key metrics—glucose levels, weight, blood pressure, meals, and medication—through intuitive and intelligent interfaces. The app's core strength is its use of cutting-edge AI to reduce the manual effort of logging, coupled with clear, data-driven visualizations for monitoring health trends.
This report details the technical architecture, components, and services of the frontend prototype.
2. Frontend Technology Stack
Core Framework: React 19 (react, react-dom)
Language: TypeScript
Styling: Tailwind CSS for a utility-first, responsive design system.
AI Integration: @google/genai SDK for all interactions with the Google Gemini family of models.
Charting/Visualization: Recharts for interactive and responsive data charts.
Build/Module System: ES Modules with an importmap for dependency management directly in the browser.
3. Project Structure
The application follows a standard component-based architecture:
/ (root): Contains index.html, index.tsx (entry point), App.tsx (main component), and types.ts.
/components: Contains all reusable React components, organized by feature (e.g., Dashboard.tsx, GlucoseLogModal.tsx, LogEntry.tsx).
/services: Contains modules that interface with external APIs, specifically geminiService.ts.
/data: Contains static data, such as the list of UK medications for autocomplete.
4. Core Architecture & State Management
App.tsx (Main Component): Acts as the root of the application. It is responsible for:
State Management: All primary application state (arrays of glucoseReadings, meals, medications, etc.) is managed using React's useState hook. State modification functions (e.g., addGlucoseReading) are memoized with useCallback for performance. Note: For a production application, this local state should be replaced with a more robust state management library (e.g., Zustand, Redux Toolkit) synchronized with a backend.
Modal Management: State flags (e.g., isGlucoseModalOpen) control the visibility of all logging modals.
Page Routing: A simple state-based router (activePage) determines which of the three main pages (Dashboard, Activity, History) is rendered.
Logging Flow:
The user initiates a log via the floating PlusIcon, which opens the ActionBottomSheet.
Selecting an action (e.g., "Log Glucose") sets the corresponding modal state to true.
The relevant modal (e.g., GlucoseLogModal) opens, providing a focused UI for the specific logging task.
The "History" page offers an alternative flow for back-dating entries via the LateEntryForm component, which reuses the same AI-powered logic.
5. AI Service Integration (services/geminiService.ts)
This service is the application's intelligent core, encapsulating all communication with the Gemini API. All functions are async and designed to return structured JSON data.
Image Validation:
isImageOfGlucoseMeter, isImageOfFood, etc., act as guards. They perform a quick, targeted check with the Gemini gemini-2.5-flash model to ensure the user has uploaded a relevant image before proceeding with more complex analysis. This improves UX by providing fast, specific feedback.
Data Extraction from Images (Vision):
parseGlucoseReadingFromImage, parseWeightFromImage, parseBloodPressureFromImage: These functions send an image (as a base64 string) and a carefully crafted text prompt to the gemini-2.5-flash model.
The prompt instructs the model to act as an expert and extract specific information.
Crucially, they use the responseSchema configuration to force Gemini to return a valid, structured JSON object, which eliminates the need for fragile string parsing on the frontend.
Data Extraction from Text (NLU):
parseGlucoseReadingFromText, parseMealFromText, etc.: These functions take a user's text input (from voice transcription or typing) and send it to gemini-2.5-flash.
Similar to the image functions, they use responseSchema to get structured JSON back, turning natural language into usable data.
Meal Analysis:
analyzeMealPhoto and parseMealFromText: These are the most complex AI functions. They instruct Gemini to act as an expert nutritionist, identify individual food items, estimate their nutritional content, and provide a total for the meal. The responseSchema here is a nested object, demonstrating the model's ability to handle complex data structures.
6. Real-time Voice Input (Gemini Live API)
Implementation: The GlucoseLogModal, WeightLogModal, and LateEntryForm components implement real-time voice-to-text.
Connection: They use ai.live.connect to establish a persistent WebSocket connection to the 'gemini-2.5-flash-native-audio-preview-09-2025' model.
Audio Processing:
navigator.mediaDevices.getUserMedia captures raw audio from the microphone.
An AudioContext and ScriptProcessorNode process the audio into chunks.
Each chunk is converted to a 16-bit PCM integer array and then base64-encoded.
The encoded audio Blob is sent to the Gemini Live API via session.sendRealtimeInput.
Transcription: The onmessage callback receives server messages containing the inputTranscription. The component state (transcript) is updated in real-time to provide immediate user feedback.
Workflow: When the user stops listening, the component checks if a final transcript exists and passes it to the relevant text parsing function in geminiService.ts (e.g., parseGlucoseReadingFromText).
Part 2: Backend Development Specification & Instructions
To: Backend Development Team
From: Senior Frontend Engineer
Subject: Specification for PharrroHealth Backend Services
1. Overview & High-Level Goals
The existing PharrroHealth frontend is a feature-complete prototype that operates with in-memory state. The primary objective for the backend team is to build a secure, scalable, and persistent backend that will serve as the "source of truth" for all user data.
The single most critical security requirement is to move all Gemini API interactions from the client to the backend. The Gemini API key must NEVER be exposed in the frontend code.
2. Recommended Technology Stack
Runtime: Node.js (LTS version)
Framework: Express.js or Fastify (for building RESTful APIs).
Database: PostgreSQL (for its relational integrity) or Firebase Firestore (for rapid development).
Authentication: JWT (JSON Web Tokens) based authentication.
File Storage: A cloud-based object storage solution like Google Cloud Storage or Amazon S3.
3. Data Models (Database Schema)
The following tables/collections are required.
users
| Column | Type | Notes |
| :--- | :--- | :--- |
| id | UUID | Primary Key |
| email | VARCHAR | Unique, Indexed |
| password_hash | VARCHAR | Store hashed passwords only (e.g., using bcrypt) |
| created_at | TIMESTAMP | |
| updated_at | TIMESTAMP | |
logs (A single, polymorphic table is recommended for the activity feed)
| Column | Type | Notes |
| :--- | :--- | :--- |
| id | UUID | Primary Key |
| user_id | UUID | Foreign Key to users.id |
| timestamp | TIMESTAMP | The time of the event, provided by user |
| type | VARCHAR | Enum: 'glucose', 'meal', 'medication', 'weight', 'blood_pressure' |
| data | JSONB | Stores the specific data for the log type |
| created_at | TIMESTAMP | |
Example data for type: 'glucose':
code
JSON
{
  "value": 5.2,
  "displayUnit": "mmol/L",
  "context": "fasting",
  "source": "voice",
  "transcript": "My sugar was 5.2 this morning before breakfast"
}
Example data for type: 'meal':
code
JSON
{
  "photoUrl": "https://storage.googleapis.com/...",
  "mealType": "lunch",
  "foodItems": [...],
  "totalNutrition": {...},
  "source": "photo_analysis"
}
user_medications
| Column | Type | Notes |
| :--- | :--- | :--- |
| id | UUID | Primary Key |
| user_id | UUID | Foreign Key to users.id |
| name | VARCHAR | |
| dosage | NUMERIC | |
| unit | VARCHAR | e.g., 'mg', 'units' |
| created_at | TIMESTAMP | |
| updated_at | TIMESTAMP | |
4. API Endpoint Specifications
All endpoints should be prefixed with /api. All endpoints (except auth) must be protected and require a valid JWT Authorization: Bearer <token> header.
4.1 Authentication
POST /auth/register
Body: { "email": "...", "password": "..." }
Action: Hash password, create new user.
Response (201): { "user": {...}, "token": "..." }
POST /auth/login
Body: { "email": "...", "password": "..." }
Action: Validate credentials.
Response (200): { "user": {...}, "token": "..." }
4.2 Logs
GET /logs
Query Params: ?page=1&limit=10
Action: Retrieve all logs for the authenticated user, sorted by timestamp descending. Implement pagination.
Response (200): { "logs": [...], "totalPages": 5, "currentPage": 1 }
POST /logs
Body: { "timestamp": "ISO_STRING", "type": "glucose", "data": {...} }
Action: Create a new log entry for the user.
Response (201): The newly created log object.
4.3 User Medications
GET /medications
Action: Get all medications for the user.
Response (200): [ { "id": "...", "name": "...", ... } ]
POST /medications
Body: { "name": "Metformin", "dosage": 500, "unit": "mg" }
Action: Create a new medication.
Response (201): The new medication object.
DELETE /medications/:id
Action: Delete a medication.
Response (204): No Content.
4.4 Gemini AI Service Proxies
This is the most critical section. The logic from the frontend's /services/geminiService.ts must be moved to the backend. The frontend will now call these backend endpoints instead of the Gemini API directly.
POST /analyze/glucose-from-image
Body: { "image": "BASE64_STRING", "mimeType": "image/jpeg" }
Backend Action:
Receive the base64 image.
Call the internal parseGlucoseReadingFromImage function (ported from the frontend service) using the server-side Gemini API key.
Return the structured result.
Response (200): { "value": 7.8, "unit": "mmol/L", "context": "after_meal" }
Error Response (400/500): { "error": "Could not parse reading from image." }
POST /analyze/meal-from-image
Body: { "image": "BASE64_STRING", "mimeType": "image/jpeg" }
Backend Action: Call internal analyzeMealPhoto function.
Response (200): { "foodItems": [...], "totalNutrition": {...} }
POST /analyze/glucose-from-text
Body: { "description": "My sugar was 7.8 after dinner" }
Backend Action: Call internal parseGlucoseReadingFromText function.
Response (200): { "value": 7.8, "unit": "mmol/L", "context": "after_meal" }
(The pattern above must be repeated for all other analysis functions):
POST /analyze/weight-from-image
POST /analyze/bp-from-image
POST /analyze/weight-from-text
POST /analyze/bp-from-text
POST /analyze/meal-from-text
The frontend is already built to interact with these exact API shapes. The primary tasks are to implement the server, database, authentication, and port the AI service logic behind these secure, authenticated endpoints.